{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Survival on the Titanic\n",
    "\n",
    "### History\n",
    "Perhaps one of the most infamous shipwrecks in history, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 people on board. Interestingly, by analysing the probability of survival based on few attributes like gender, age, and social status, we can make very accurate predictions on which passengers would survive. Some groups of people were more likely to survive than others, such as women, children, and the upper-class. Therefore, we can learn about the society priorities and privileges at the time.\n",
    "\n",
    "## Here We're Going to Build a Machine Learning Solution Pipeline, to engineer the features in the dataset and predict who is more likely to Survive the catastrophe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install feature_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to divide train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# to build the models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# to evaluate the models\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# to persist the model and the scaler\n",
    "import joblib\n",
    "\n",
    "# ========== NEW IMPORTS ========\n",
    "# Compare with manual solution\n",
    "\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# for the preprocessors\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# for imputation\n",
    "from feature_engine.imputation import (\n",
    "    CategoricalImputer,\n",
    "    AddMissingIndicator,\n",
    "    MeanMedianImputer)\n",
    "\n",
    "# for encoding categorical variables\n",
    "from feature_engine.encoding import (\n",
    "    RareLabelEncoder,\n",
    "    OneHotEncoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feature_engine\n",
    "feature_engine.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data - it is available open source and online\n",
    "\n",
    "#data = pd.read_csv('https://www.openml.org/data/get_csv/16826755/phpMYEkMl')\n",
    "#data = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
    "data = pd.read_csv('../Data/titanic.csv')\n",
    "# display data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace interrogation marks by NaN values\n",
    "\n",
    "data = data.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain only the first cabin if more than\n",
    "# 1 are available per passenger\n",
    "\n",
    "def get_first_cabin(row):\n",
    "    try:\n",
    "        return row.split()[0]\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "data['Cabin'] = data['Cabin'].apply(get_first_cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts the title (Mr, Ms, etc) from the name variable\n",
    "\n",
    "def get_title(passenger):\n",
    "    line = passenger\n",
    "    if re.search('Mrs', line):\n",
    "        return 'Mrs'\n",
    "    elif re.search('Mr', line):\n",
    "        return 'Mr'\n",
    "    elif re.search('Miss', line):\n",
    "        return 'Miss'\n",
    "    elif re.search('Master', line):\n",
    "        return 'Master'\n",
    "    else:\n",
    "        return 'Other'\n",
    "    \n",
    "data['Title'] = data['Name'].apply(get_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cabin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast numerical variables as floats\n",
    "\n",
    "data['Fare'] = data['Fare'].astype('float')\n",
    "data['Age'] = data['Age'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary variables\n",
    "\n",
    "data.drop(labels=['PassengerId','Name','Ticket'], axis=1, inplace=True)\n",
    "\n",
    "# display data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the data set\n",
    "\n",
    "# data.to_csv('titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of variables to be used in the pipeline's transformers\n",
    "\n",
    "NUMERICAL_VARIABLES = ['Age', 'Fare']\n",
    "\n",
    "CATEGORICAL_VARIABLES = ['Sex', 'Cabin', 'Embarked', 'Title']\n",
    "\n",
    "CABIN = ['Cabin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('Survived', axis=1),  # predictors\n",
    "    data['Survived'],  # target\n",
    "    test_size=0.2,  # percentage of obs in test set\n",
    "    random_state=0)  # seed to ensure reproducibility\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessors\n",
    "\n",
    "### Class to extract the letter from the variable Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractLetterTransformer(BaseEstimator, TransformerMixin):\n",
    "    # Inherit from BaseEstimator to define the paremeters\n",
    "    # TransformerMixin to inherit the fit_transform functionality\n",
    "    # Extract first letter of variable\n",
    "\n",
    "    def __init__(self, variables):\n",
    "        \n",
    "        if not isinstance(variables, list):\n",
    "            raise ValueError('variables should be a list')\n",
    "        \n",
    "        self.variables = variables\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # we need this step to fit the sklearn pipeline\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "\n",
    "        # so that we do not over-write the original dataframe\n",
    "        X = X.copy()\n",
    "        \n",
    "        for feature in self.variables:\n",
    "            X[feature] = X[feature].str[0]\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "- Impute categorical variables with string missing\n",
    "- Add a binary missing indicator to numerical variables with missing data\n",
    "- Fill NA in original numerical variable with the median\n",
    "- Extract first letter from cabin\n",
    "- Group rare Categories\n",
    "- Perform One hot encoding\n",
    "- Scale features with standard scaler\n",
    "- Fit a Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the pipeline\n",
    "titanic_pipe = Pipeline([\n",
    "\n",
    "    # ===== IMPUTATION =====\n",
    "    # impute categorical variables with string missing\n",
    "    ('categorical_imputation', CategoricalImputer(\n",
    "        imputation_method='missing', variables=CATEGORICAL_VARIABLES)),\n",
    "\n",
    "    # add missing indicator to numerical variables\n",
    "    ('missing_indicator', AddMissingIndicator(variables=NUMERICAL_VARIABLES)),\n",
    "\n",
    "    # impute numerical variables with the median\n",
    "    ('median_imputation', MeanMedianImputer(\n",
    "        imputation_method='median', variables=NUMERICAL_VARIABLES)),\n",
    "\n",
    "\n",
    "    # Extract letter from cabin\n",
    "    ('extract_letter', ExtractLetterTransformer(variables=CABIN)),\n",
    "\n",
    "\n",
    "    # == CATEGORICAL ENCODING ======\n",
    "    # remove categories present in less than 5% of the observations (0.05)\n",
    "    # group them in one category called 'Rare'\n",
    "    ('rare_label_encoder', RareLabelEncoder(\n",
    "        tol=0.05, n_categories=1, variables=CATEGORICAL_VARIABLES)),\n",
    "\n",
    "\n",
    "    # encode categorical variables using one hot encoding into k-1 variables\n",
    "    ('categorical_encoder', OneHotEncoder(\n",
    "        drop_last=True, variables=CATEGORICAL_VARIABLES)),\n",
    "\n",
    "    # scale\n",
    "    ('scaler', StandardScaler()),\n",
    "\n",
    "    ('Logit', LogisticRegression(C=0.0005, random_state=0)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the pipeline\n",
    "titanic_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's save the pipeline\n",
    "joblib.dump(titanic_pipe, 'titanic_pipe.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load a saved model/pipeline\n",
    "loaded_model = joblib.load('titanic_pipe.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions and evaluate model performance\n",
    "\n",
    "Determine:\n",
    "- roc-auc\n",
    "- accuracy\n",
    "\n",
    "**Important, remember that to determine the accuracy, you need the outcome 0, 1, referring to survived or not. But to determine the roc-auc you need the probability of survival.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for train set\n",
    "class_ = titanic_pipe.predict(X_train)\n",
    "pred = titanic_pipe.predict_proba(X_train)[:,1]\n",
    "\n",
    "# determine mse and rmse\n",
    "print('train roc-auc: {}'.format(roc_auc_score(y_train, pred)))\n",
    "print('train accuracy: {}'.format(accuracy_score(y_train, class_)))\n",
    "print()\n",
    "\n",
    "# make predictions for test set\n",
    "class_ = titanic_pipe.predict(X_test)\n",
    "pred = titanic_pipe.predict_proba(X_test)[:,1]\n",
    "\n",
    "# determine mse and rmse\n",
    "print('test roc-auc: {}'.format(roc_auc_score(y_test, pred)))\n",
    "print('test accuracy: {}'.format(accuracy_score(y_test, class_)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Bonus Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your own MeanImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Numerical missing value imputer.\"\"\"\n",
    "\n",
    "    def __init__(self, variables):\n",
    "        if not isinstance(variables, list):\n",
    "            raise ValueError('variables should be a list')\n",
    "        self.variables = variables\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # persist mean values in a dictionary\n",
    "        self.imputer_dict_ = X[self.variables].mean().to_dict()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for feature in self.variables:\n",
    "            X[feature].fillna(self.imputer_dict_[feature],\n",
    "                              inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your RareLabelCategoricalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RareLabelCategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Groups infrequent categories into a single string\"\"\"\n",
    "\n",
    "    def __init__(self, variables, tol=0.05):\n",
    "\n",
    "        if not isinstance(variables, list):\n",
    "            raise ValueError('variables should be a list')\n",
    "        \n",
    "        self.tol = tol\n",
    "        self.variables = variables\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # persist frequent labels in dictionary\n",
    "        self.encoder_dict_ = {}\n",
    "\n",
    "        for var in self.variables:\n",
    "            # the encoder will learn the most frequent categories\n",
    "            t = pd.Series(X[var].value_counts(normalize=True)) \n",
    "            # frequent labels:\n",
    "            self.encoder_dict_[var] = list(t[t >= self.tol].index)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for feature in self.variables:\n",
    "            X[feature] = np.where(\n",
    "                X[feature].isin(self.encoder_dict_[feature]),\n",
    "                                X[feature], \"Rare\")\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your own CategoricalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"String to numbers categorical encoder.\"\"\"\n",
    "\n",
    "    def __init__(self, variables):\n",
    "\n",
    "        if not isinstance(variables, list):\n",
    "            raise ValueError('variables should be a list')\n",
    "        \n",
    "        self.variables = variables\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        temp = pd.concat([X, y], axis=1)\n",
    "        temp.columns = list(X.columns) + [\"target\"]\n",
    "\n",
    "        # persist transforming dictionary\n",
    "        self.encoder_dict_ = {}\n",
    "\n",
    "        for var in self.variables:\n",
    "            t = temp.groupby([var])[\"target\"].mean().sort_values(ascending=True).index\n",
    "            self.encoder_dict_[var] = {k: i for i, k in enumerate(t, 0)}\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # encode labels\n",
    "        X = X.copy()\n",
    "        for feature in self.variables:\n",
    "            X[feature] = X[feature].map(self.encoder_dict_[feature])\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
