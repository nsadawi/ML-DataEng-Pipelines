{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Survival on the Titanic\n",
    "\n",
    "### History\n",
    "Perhaps one of the most infamous shipwrecks in history, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 people on board. Interestingly, by analysing the probability of survival based on few attributes like gender, age, and social status, we can make very accurate predictions on which passengers would survive. Some groups of people were more likely to survive than others, such as women, children, and the upper-class. Therefore, we can learn about the society priorities and privileges at the time.\n",
    "\n",
    "## Here We're Going to Build a Manual Machine Learning Solution, to engineer the features in the dataset and predict who is more likely to Survive the catastrophe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to divide train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# to build the models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# to evaluate the models\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# to persist the model and the scaler\n",
    "import joblib\n",
    "\n",
    "# to visualise al the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data - it is available open source and online\n",
    "#data = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
    "data = pd.read_csv('../Data/titanic.csv')\n",
    "\n",
    "# display data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace question marks by NaN values\n",
    "data = data.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cabin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain only the first cabin if more than\n",
    "# 1 are available per passenger\n",
    "\n",
    "def get_first_cabin(row):\n",
    "    try:\n",
    "        return row.split()[0]\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "data['Cabin'] = data['Cabin'].apply(get_first_cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts the title (Mr, Ms, etc) from the name variable\n",
    "def get_title(passenger):\n",
    "    line = passenger\n",
    "    if re.search('Mrs', line):\n",
    "        return 'Mrs'\n",
    "    elif re.search('Mr', line):\n",
    "        return 'Mr'\n",
    "    elif re.search('Miss', line):\n",
    "        return 'Miss'\n",
    "    elif re.search('Master', line):\n",
    "        return 'Master'\n",
    "    elif re.search('Dr', line):\n",
    "        return 'Dr'\n",
    "    else:\n",
    "        return 'Other'\n",
    "    \n",
    "data['Title'] = data['Name'].apply(get_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary variables\n",
    "data.drop(labels=['PassengerId','Name','Ticket'], axis=1, inplace=True)\n",
    "\n",
    "# display data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data set\n",
    "\n",
    "#data.to_csv('titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "### Find numerical and categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_num = [c for c in data.columns if data[c].dtypes!='O' and c!=target]\n",
    "\n",
    "vars_cat = [c for c in data.columns if data[c].dtypes=='O']\n",
    "\n",
    "print('Number of numerical variables: {}'.format(len(vars_num)))\n",
    "print('Number of categorical variables: {}'.format(len(vars_cat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find missing values in variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first in numerical variables\n",
    "\n",
    "data[vars_num].isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now in categorical variables\n",
    "\n",
    "data[vars_cat].isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine cardinality of categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[vars_cat].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the distribution of numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[vars_num].hist(bins=30, figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('Survived', axis=1),  # predictors\n",
    "    data['Survived'],  # target\n",
    "    test_size=0.2,  # percentage of obs in test set\n",
    "    random_state=0)  # seed to ensure reproducibility\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "### Extract only the letter (and drop the number) from the variable Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Cabin'] = X_train['Cabin'].str[0] # captures the first letter\n",
    "X_test['Cabin'] = X_test['Cabin'].str[0] # captures the first letter\n",
    "\n",
    "X_train['Cabin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Cabin'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in Missing data in numerical variables:\n",
    "\n",
    "- Add a binary missing indicator\n",
    "- Fill NA in original variable with the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in ['Age', 'Fare']:\n",
    "\n",
    "    # add missing indicator\n",
    "    X_train[var+'_NA'] = np.where(X_train[var].isnull(), 1, 0)\n",
    "    X_test[var+'_NA'] = np.where(X_test[var].isnull(), 1, 0)\n",
    "\n",
    "    # replace NaN by median\n",
    "    median_val = X_train[var].median()\n",
    "\n",
    "    X_train[var] = X_train[var].fillna(median_val)\n",
    "    X_test[var] = X_test[var].fillna(median_val)\n",
    "\n",
    "X_train[['Age', 'Fare']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace Missing data in categorical variables with the string **Missing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[vars_cat] = X_train[vars_cat].fillna('Missing')\n",
    "X_test[vars_cat] = X_test[vars_cat].fillna('Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rare labels in categorical variables\n",
    "\n",
    "- remove labels present in less than 5 % of the passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_frequent_labels(df, var, rare_perc):\n",
    "    \n",
    "    # function finds the labels that are shared by more than\n",
    "    # a certain % of the passengers in the dataset\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    tmp = df.groupby(var)[var].count() / len(df)\n",
    "    \n",
    "    return tmp[tmp > rare_perc].index\n",
    "\n",
    "\n",
    "for var in vars_cat:\n",
    "    \n",
    "    # find the frequent categories\n",
    "    frequent_ls = find_frequent_labels(X_train, var, 0.05)\n",
    "    \n",
    "    # replace rare categories by the string \"Rare\"\n",
    "    X_train[var] = np.where(X_train[var].isin(\n",
    "        frequent_ls), X_train[var], 'Rare')\n",
    "    \n",
    "    X_test[var] = np.where(X_test[var].isin(\n",
    "        frequent_ls), X_test[var], 'Rare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[vars_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[vars_cat].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform one hot encoding of categorical variables into k-1 binary variables\n",
    "\n",
    "- k-1, means that if the variable contains 9 different categories, we create 8 different binary variables\n",
    "- Remember to drop the original categorical variable (the one with the strings) after the encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in vars_cat:\n",
    "    \n",
    "    # to create the binary variables, we use get_dummies from pandas\n",
    "    \n",
    "    X_train = pd.concat([X_train,\n",
    "                         pd.get_dummies(X_train[var], prefix=var, drop_first=True)\n",
    "                         ], axis=1)\n",
    "    \n",
    "    X_test = pd.concat([X_test,\n",
    "                        pd.get_dummies(X_test[var], prefix=var, drop_first=True)\n",
    "                        ], axis=1)\n",
    "    \n",
    "\n",
    "X_train.drop(labels=vars_cat, axis=1, inplace=True)\n",
    "X_test.drop(labels=vars_cat, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we have one less column in the test set\n",
    "# this is because we had 1 less category in embarked.\n",
    "\n",
    "# we need to add that category manually to the test set\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we add 0 as values for all the observations, as Rare\n",
    "# was not present in the test set\n",
    "\n",
    "X_test['Embarked_Rare'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that now embarked_Rare will be at the end of the test set\n",
    "# so in order to pass the variables in the same order, we will\n",
    "# create a variables variable:\n",
    "\n",
    "variables = [c  for c in X_train.columns]\n",
    "\n",
    "variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the variables\n",
    "\n",
    "- Use the standard scaler from Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#  fit  the scaler to the train set\n",
    "scaler.fit(X_train[variables]) \n",
    "\n",
    "# transform the train and test set\n",
    "X_train = scaler.transform(X_train[variables])\n",
    "\n",
    "X_test = scaler.transform(X_test[variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Logistic Regression model\n",
    "\n",
    "- Set the regularization parameter to 0.0005\n",
    "- Set the seed to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the model\n",
    "# remember to set the random_state / seed\n",
    "\n",
    "model = LogisticRegression(C=0.005, random_state=0)\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions and evaluate model performance\n",
    "\n",
    "Determine:\n",
    "- roc-auc\n",
    "- accuracy\n",
    "\n",
    "**Important, remember that to determine the accuracy, you need the outcome 0, 1, referring to survived or not. But to determine the roc-auc you need the probability of survival.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test set\n",
    "class_ = model.predict(X_train)\n",
    "pred = model.predict_proba(X_train)[:,1]\n",
    "\n",
    "# determine mse and rmse\n",
    "print('train roc-auc: {}'.format(roc_auc_score(y_train, pred)))\n",
    "print('train accuracy: {}'.format(accuracy_score(y_train, class_)))\n",
    "print()\n",
    "\n",
    "# make predictions for test set\n",
    "class_ = model.predict(X_test)\n",
    "pred = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# determine mse and rmse\n",
    "print('test roc-auc: {}'.format(roc_auc_score(y_test, pred)))\n",
    "print('test accuracy: {}'.format(accuracy_score(y_test, class_)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of problems if we want to make future predictions\n",
    "1- Re-write a lot of code ==> repetitive\n",
    "\n",
    "2- Hard coded a lot of parameters ==> if these change we need to re-write them again.\n",
    "\n",
    "3- We may engineer a lot of variables that we actually do not need for the model.\n",
    "\n",
    "4- Additional variables may present missing data, we do not know what to do with them!\n",
    "\n",
    "**We can minimize these hurdles by using Open-source. That's what we will learn!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
